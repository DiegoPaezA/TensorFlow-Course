{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://tinyurl.com/25w9fddv\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone Project 1: Food Vision Big\n",
    "\n",
    "En el [notebook anterior](https://tinyurl.com/2huraxmc) se construyó un modelo de clasificación de imágenes Food Vision mini, el cual se entrenó con el 10% de las imágenes de Food101. En este notebook, se entrenará un modelo de clasificación de imágenes Food Vision Big, el cual se entrenará con el 100% de las imágenes de Food101.\n",
    "\n",
    "El dataset de Food101 contiene un total de 101,000 imágenes de 101 clases de comida diferentes. El dataset está dividido en 75,750 imágenes de entrenamiento y 25,250 imágenes de prueba.\n",
    "\n",
    ":eye: El objetivo del modelo a crear será vencer el rendimiento del modelo [DeepFood](https://tinyurl.com/2huraxmc), presentado en un artículo en 2016, el cual utilizó redes neuronales convolucionales entradas por 2-3 dias para alcanzar un rendimiento de 77.5% top-1 accuracy en el dataset de Food101.\n",
    "\n",
    ":key: **Nota:** [Top-1 accuracy](https://tinyurl.com/28yyvj3n) significa que el modelo predice la clase de comida correcta en la imagen de prueba.\n",
    "\n",
    "<a href=\"https://ibb.co/wpN3Tcg\"><img src=\"https://i.ibb.co/mhC1mNT/foovision.png\" alt=\"foovision\" border=\"0\"></a>\n",
    "\n",
    "Adicionalmente, se utilizarán las siguientes técnicas para mejorar el rendimiento del modelo:\n",
    "\n",
    "1. Prefetching: [Prefetching](https://tinyurl.com/2huraxmc) es una técnica que se utiliza para acelerar el entrenamiento de modelos de aprendizaje profundo. En lugar de que el modelo espere a que los datos estén listos para ser procesados, los datos se cargan en segundo plano mientras el modelo está entrenando. Esto significa que el modelo no tiene que esperar a que los datos estén listos para ser procesados, lo que acelera el tiempo de entrenamiento.\n",
    "\n",
    "2. Mixed precision training: [Mixed precision training](https://tinyurl.com/2huraxmc) es una técnica que se utiliza para acelerar el entrenamiento de modelos de aprendizaje profundo. En lugar de entrenar un modelo con datos de punto flotante de 32 bits (float32), se entrena con datos de punto flotante de 16 bits (float16). Esto significa que el modelo se entrena con la mitad de la precisión, pero a la mitad del tiempo.\n",
    "\n",
    "**El notebook cubre los siguientes temas:**\n",
    "\n",
    "- Utilizar datasets de TensorFlow para descargar y explorar los datos. \n",
    "- Crear una función de preprocesamiento para los datos. \n",
    "- Batching y Preparar los datos para el modelo.\n",
    "- Creación de callbacks de modelado.\n",
    "- Configurar entrenamiento con mixed precision.\n",
    "- Construir un modelo de extracción de características. (ver: [Feature extraction transfer learning](https://tinyurl.com/2egqg77w))\n",
    "- Fine-tuning el modelo de extracción de características. (ver: [Fine-tuning transfer learning](https://tinyurl.com/2g8ohpsx))\n",
    "- Visualizar los resultados de entrenamiento con TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8173103b97bf613cde717d81021a4a8a77760fbef76bd6423549d26b1e1d3fec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
