{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://tinyurl.com/2fa4l47p\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning con TensorFlow\n",
    "\n",
    "## Parte 3. Scaling up\n",
    "\n",
    "En la parte 1 y 2, hemos visto la potencia de transfer learning con TensorFlow. En esta parte, vamos a ver cómo escalarlo para trabajar con conjuntos de datos más grandes.\n",
    "\n",
    "Es una práctica común en machine learning y deep learning, crear un modelo que funcione con un conjunto de datos pequeños antes de escalarlo para trabajar con conjuntos de datos más grandes.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/06-ml-serial-experimentation.png\" alt=\"scaling-up\" border=\"0\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8173103b97bf613cde717d81021a4a8a77760fbef76bd6423549d26b1e1d3fec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
